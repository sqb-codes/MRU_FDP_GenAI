{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fdb2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install google-generativeai --use-deprecated=legacy-resolver\n",
    "# !pip install -U sentence-transformers==2.2.2 --use-deprecated=legacy-resolver\n",
    "# !pip install InstructorEmbedding --use-deprecated=legacy-resolver\n",
    "!pip install faiss-cpu --use-deprecated=legacy-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5666f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "\n",
    "api_key = 'AIzaSyBQsnIAq_p3rY5YQVQiBCJhuaZIQ_S2XCk' # get this free api key from https://makersuite.google.com/\n",
    "\n",
    "llm = GooglePalm(google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be1278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Boss's name],\n",
      "\n",
      "I am writing to request a leave of absence from [start date] to [end date].\n",
      "\n",
      "The reason for my leave is [reason].\n",
      "\n",
      "I will be available by email and phone at [email address] and [phone number] if needed.\n",
      "\n",
      "Thank you for your approval.\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a 4 line of mail to apply for leave\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59100dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed657cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"prompt_engineering_dataset.csv\", source_column=\"Prompt\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb30d79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 0}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a7f945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2085c948fbd540c3a0652c4a35a5d411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7c1b22cb274cb1a0818f4b54b3ac10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca552ec8bf840e7a730e7a7277e186f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f674f2ae97b4e10a6a44a7510b50305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e170f50f15441cb922a198253dc3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6713b25f2c2744b4824f0d4b3ab777f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ee7f5756674ec8998139fa3fea4dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0614ee8d8b014949b71b60e46843de3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a5fbc4f64f463e81adc73c348fd388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf247017d354cdaa63624b45fa457d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c825b120ee9e4118b247d59332c1d500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bbde1df9724cffbe0a8c750a9fe49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdc7ebc2d4d43cf9791a17b947079da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78da535ad9504d6998258012a6d0d648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instruct_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "em = instruct_embeddings.embed_query(\"Where do you see yourself after 5 years ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73a49eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectors using FAISS - Facebook AI Similarity Search\n",
    "# it contains algorithm that can search through a set of vectors\n",
    "# it uses nearest-neighbor search implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8574d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(documents=data, embedding=instruct_embeddings)\n",
    "retriever = vectordb.as_retriever(score_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2b10124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': \"I'm feeling sad today.\", 'row': 2}, page_content=\"Prompt: I'm feeling sad today.\\nResponse: I'm sorry to hear that you're feeling down. It's okay to have off days, and it's important to take time to care for yourself.\"), Document(metadata={'source': \"I'm feeling sad today.\", 'row': 23}, page_content=\"Prompt: I'm feeling sad today.\\nResponse: I'm sorry to hear that you're feeling down. It's okay to have off days, and it's important to take time to care for yourself.\"), Document(metadata={'source': \"I'm feeling sad today.\", 'row': 29}, page_content=\"Prompt: I'm feeling sad today.\\nResponse: I'm sorry to hear that you're feeling down. It's okay to have off days, and it's important to take time to care for yourself.\"), Document(metadata={'source': \"I'm feeling sad today.\", 'row': 47}, page_content=\"Prompt: I'm feeling sad today.\\nResponse: I'm sorry to hear that you're feeling down. It's okay to have off days, and it's important to take time to care for yourself.\")]\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"I am not well\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c2eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = retriever.get_relevant_documents(\"I am not well\")\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4edb3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrieval QA chain along with prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c6b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What should be my plan for next 5 years ?',\n",
       " 'result': 'You should focus on advancing your career and possibly settling down with a family.',\n",
       " 'source_documents': [Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 0}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 15}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 39}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 51}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"In the following context and question, generate an answer based on the current context only.\n",
    "In the answer try to provide as much as text as possible from \"response\" section in source document context.\n",
    "If answer not found in context either state I don't know or try to make up an answer\n",
    "CONTETXT : {context}\n",
    "QUESTION : {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template, input_variables = [\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_kwargs = {\"prompt\" : prompt}\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    retriever=retriever, \n",
    "                                    input_key=\"query\", \n",
    "                                    return_source_documents=True,\n",
    "                                   chain_type_kwargs=chain_kwargs)\n",
    "\n",
    "chain(\"What should be my plan for next 5 years ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f898ad66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'I am not well but What should be my plan for next 5 years ?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 0}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 15}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 39}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.'),\n",
       "  Document(metadata={'source': 'Where do you see yourself in 5 years?', 'row': 51}, page_content='Prompt: Where do you see yourself in 5 years?\\nResponse: In 5 years, I see myself advancing in my career and possibly settling down with a family.')]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"I am not well but What should be my plan for next 5 years ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cdaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
